{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelGindin/MS-segmentation-model/blob/main/MS_segmentation_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Dependencies"
      ],
      "metadata": {
        "id": "6Htrkv0aVr2Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "391Go7A7nsIE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from io import FileIO\n",
        "from PIL import Image \n",
        "import sys, os\n",
        "import pathlib\n",
        "import cv2 \n",
        "import glob\n",
        "from skimage.io import imread_collection\n",
        "from nibabel.testing import data_path\n",
        "import nibabel as nib\n",
        "import pylab as plt\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Add, PReLU, Conv2DTranspose, Concatenate, MaxPooling2D, UpSampling2D, Dropout\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.callbacks import Callback\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P4opAmh-ACW"
      },
      "source": [
        "## Access Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJR6tS5awlrG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1ssRFuf64ip"
      },
      "source": [
        "# Define parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u5bqlAq66j-"
      },
      "outputs": [],
      "source": [
        "LearningRate = 0.00001 #  check: 0.00001\n",
        "NUM_EPOCHS = 100        #  check: 50 100 \n",
        "BATCH_SIZE = 32        #  check: 16 32\n",
        "crop_size = 32         #  check: 32 64\n",
        "crop_precentage = 0.2 #  check: 0.3 0.5 0.6 \n",
        "Gamma=4.0\n",
        "\n",
        "#chosing optimizer\n",
        "ChosenOptimizer = Adam(learning_rate = LearningRate)\n",
        "loss_function = tf.keras.losses.BinaryFocalCrossentropy(  gamma=Gamma, from_logits=False)\n",
        "#loss_function= tf.keras.losses.BinaryCrossentropy(from_logits=False) \n",
        "#loss_function= 'mse'\n",
        "ModolalityType ='-T2'  #'-T1' #'-Flair' \n",
        "\n",
        "ModelDepth = 4\n",
        "\n",
        "run_folder_output = \"BinaryFocalCrossentropy\"+ '-Ep'+str(NUM_EPOCHS)+'-B'+str(BATCH_SIZE)+'-CrSize'+str(crop_size)+'-CrPrecent'+str(crop_precentage)+'-LR'+str(LearningRate)+ModolalityType+'-Gamma'+str(Gamma)+'-Depth'+str(ModelDepth) #need to change each run time\n",
        "\n",
        "#creating path of output\n",
        "weights_path = '/content/drive/MyDrive/New_Final_Project_Weights/Modality/'+run_folder_output\n",
        "Path(weights_path).mkdir(parents=True,exist_ok=True)\n",
        "numberWeight = 95\n",
        "filePath = 'weights.'+str(numberWeight)+'.hdf5'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkBXkhdrxJzs"
      },
      "source": [
        "# Access to DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9y8VzUpGiLJA"
      },
      "outputs": [],
      "source": [
        "#Loading Images from db\n",
        "def upload_db_images(path, MRI_modality,couples):\n",
        "    listImages = []\n",
        "    listMasks = []\n",
        "    listFilesImages = []\n",
        "    listFilesMasks = []\n",
        "    for r,d,f in os.walk(path):\n",
        "        x = None\n",
        "        y = None\n",
        "        for files in f:\n",
        "            if (MRI_modality+'.nii') in files :\n",
        "                ex = os.path.join(r, files)\n",
        "                if 'Seg' in files:\n",
        "                  listFilesMasks.append(r)\n",
        "                  listMasks.append( nib.load(ex))\n",
        "                  y = nib.load(ex)\n",
        "                  #print(ex)\n",
        "                else:\n",
        "                  listFilesImages.append(r)\n",
        "                  listImages.append(nib.load(ex))\n",
        "                  x = nib.load(ex)\n",
        "                  #print(ex)\n",
        "        if(x!=None and y!=None):\n",
        "          couples.append([x,y])\n",
        "    return listImages,listMasks,listFilesImages,listFilesMasks,couples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I00Q5week_eB"
      },
      "source": [
        "**Loading images**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "couples=[]"
      ],
      "metadata": {
        "id": "jG1pYQ3EYdKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K985dODIlA5p"
      },
      "outputs": [],
      "source": [
        "listImages,listMasks,listFilesImages,listFilesMasks,couples = upload_db_images(r'/content/drive/MyDrive/DB_final_project/Brain MRI Dataset of Multiple Sclerosis with Consensus Manual Lesion Segmentation and Patient Meta Information',ModolalityType,couples)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "listImages2,listMasks2,listFilesImages2,listFilesMasks2,couples = upload_db_images(r'/content/drive/MyDrive/DB_final_project/DB-Train',ModolalityType,couples)"
      ],
      "metadata": {
        "id": "WHxajLDkYg7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preproccessed the data part: crop and resize augmentation then normalize"
      ],
      "metadata": {
        "id": "Wa2egZqwVMuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#crop black background\n",
        "def crop_image(image, mask):\n",
        "    image2 = image[:,:,image.shape[2]//2]\n",
        "    max_cols = np.amax(image2,axis=0)\n",
        "    nonzero_cols = np.nonzero(max_cols)\n",
        "    first_col = nonzero_cols[0].min()\n",
        "    last_col = nonzero_cols[0].max()\n",
        "    max_rows = np.amax(image2, axis=1)\n",
        "    nonzero_rows = np.nonzero(max_rows)\n",
        "    first_row = nonzero_rows[0].min()\n",
        "    last_row = nonzero_rows[0].max()\n",
        "    image = image[first_row:last_row,first_col:last_col:,]\n",
        "    mask = mask[first_row:last_row,first_col:last_col:,]\n",
        "    return np.uint8(image),mask"
      ],
      "metadata": {
        "id": "fTXdMczxX2OO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W13OFHwPsN06"
      },
      "outputs": [],
      "source": [
        "#Resizing images to the same size\n",
        "def resize(input_image, input_mask):\n",
        "   input_image = tf.image.resize(input_image, (256, 256), method=\"nearest\")\n",
        "   input_mask = tf.image.resize(input_mask, (256, 256), method=\"nearest\")\n",
        "   return input_image, input_mask"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "range(len(inputsCouples))"
      ],
      "metadata": {
        "id": "cCcFolR7i2eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AugmentateImage(inputImage,inputMask):\n",
        "    couples = []\n",
        "    \n",
        "    for i in range(0, 256-crop_size, crop_size//2):\n",
        "        for j in range(0, 256-crop_size, crop_size//2):\n",
        "            newImage = np.array(inputImage[i:i+crop_size, j:j+crop_size])\n",
        "            newMask = np.array(inputMask[i:i+crop_size, j:j+crop_size])\n",
        "\n",
        "            #newImage= (inputImage.crop(box))\n",
        "            #newMask= (inputMask.crop(box))\n",
        "            couples.append((newImage,newMask))\n",
        "\n",
        "    return couples\n",
        "\n",
        "def AugmentateImages(inputsCouples):\n",
        "    newCouples = []\n",
        "    for i in range(len(inputsCouples)):\n",
        "        newImages = AugmentateImage(inputsCouples[i][0], inputsCouples[i][1])\n",
        "        shape = newImages[0][1].shape\n",
        "        for index in range(len(newImages)):\n",
        "            if np.count_nonzero(newImages[index][1]) > crop_precentage*np.prod(shape):\n",
        "                newCouples.append(newImages[index])\n",
        "    return newCouples\n",
        "\n",
        "inputsCouples = AugmentateImages(inputsCouples)\n"
      ],
      "metadata": {
        "id": "2RFfvYpyhfwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('inputsCouples: '+str(len(inputsCouples)))"
      ],
      "metadata": {
        "id": "PHlzjcFRhjBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMA_RccIwMNz"
      },
      "outputs": [],
      "source": [
        "#inputImages = inputImages[0:160] \n",
        "#inputMasks = inputMasks[0:160]\n",
        "\n",
        "combinedSet = zip(inputImages,inputMasks)\n",
        "combinedSet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BknarsOP6dzx"
      },
      "source": [
        "Noralize Images to be between 0...1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "694fLGXam7PM"
      },
      "outputs": [],
      "source": [
        "#Normalization\n",
        "def normalize(input_image, input_mask):\n",
        "   input_image = np.uint8(input_image)\n",
        "   input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "   input_mask_new = input_mask #- 1\n",
        "  #  return np.expand_dims(input_image,-1), np.expand_dims(input_mask_new,-1)\n",
        "   return tf.cast(input_image, tf.float32), tf.cast(input_mask_new, tf.float32)\n",
        "\n",
        "#Doing normalization\n",
        "newCouples = []\n",
        "for imgNumber in range(len(inputsCouples)):\n",
        "  normalizedImg , normalizedMask = normalize(inputsCouples[imgNumber][0],inputsCouples[imgNumber][1])\n",
        "  newCouples.append((normalizedImg, normalizedMask))\n",
        "\n",
        "\n",
        "inputsCouples = newCouples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B11GTjFst_M0"
      },
      "source": [
        "# Prepare the U-Net Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_H9kPE_3-R3"
      },
      "outputs": [],
      "source": [
        "# UNet: code from https://github.com/pietz/unet-keras\n",
        "# names added\n",
        "def get_unet_model(input_channel_num=1, out_ch=1, start_ch=64, depth=ModelDepth, inc_rate=2., activation='relu',\n",
        "         dropout=0.5, batchnorm=False, maxpool=True, upconv=True, residual=False):\n",
        "    def _conv_block(m, dim, acti, bn, res,name_post, do=0):\n",
        "        n = Conv2D(dim, 3, activation=acti, padding='same', name=f\"conv_{name_post}_1\")(m)\n",
        "        n = BatchNormalization()(n) if bn else n\n",
        "        n = Dropout(do, name=f\"dropout_{name_post}\")(n) if do else n\n",
        "        n = Conv2D(dim, 3, activation=acti, padding='same', name=f\"conv_{name_post}_2\")(n)\n",
        "        n = BatchNormalization()(n) if bn else n\n",
        "\n",
        "        return Concatenate()([m, n]) if res else n\n",
        "\n",
        "    def _level_block(m, dim, depth, inc, acti, do, bn, mp, up, res):\n",
        "        if depth > 0:\n",
        "            n = _conv_block(m, dim, acti, bn, res, f\"down{depth}\")\n",
        "            m = MaxPooling2D(name=f\"maxpool_{depth}\")(n) if mp else Conv2D(dim, 3, strides=2, padding='same')(n)\n",
        "            m = _level_block(m, int(inc * dim), depth - 1, inc, acti, do, bn, mp, up, res)\n",
        "            if up:\n",
        "                m = UpSampling2D(name=f\"upsampling_{depth}\")(m)\n",
        "                m = Conv2D(dim, 2, activation=acti, padding='same', name=f\"upconv_{depth}\")(m)\n",
        "            else:\n",
        "                m = Conv2DTranspose(dim, 3, strides=2, activation=acti, padding='same')(m)\n",
        "            n = Concatenate(name=f\"concat_{depth}\")([n, m])\n",
        "            m = _conv_block(n, dim, acti, bn, res, f\"up{depth}\")\n",
        "        else:\n",
        "            m = _conv_block(m, dim, acti, bn, res, \"bottom\", do)\n",
        "\n",
        "        return m\n",
        "\n",
        "    i = Input(shape=(None, None, input_channel_num))\n",
        "    o = _level_block(i, start_ch, depth, inc_rate, activation, dropout, batchnorm, maxpool, upconv, residual)\n",
        "    o = Conv2D(out_ch, 1,activation='sigmoid', name=f\"conv_output\")(o)\n",
        "    model = Model(inputs=i, outputs=o, name=\"encoder_decoder\")\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get unet model object"
      ],
      "metadata": {
        "id": "hnv95ky1OazX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PhTXcKPuQbU"
      },
      "outputs": [],
      "source": [
        "unet_model = get_unet_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gQR6TPKuiFs"
      },
      "outputs": [],
      "source": [
        "unet_model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHXj4lKQutWM"
      },
      "source": [
        "Visualize The ModelVisualize The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrFttpeoutLU"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(unet_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining methods to help evaluate the model"
      ],
      "metadata": {
        "id": "PcsnDPSIYCdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
        "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
        "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)"
      ],
      "metadata": {
        "id": "sG3gaBcmWuNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = []\n",
        "metric.append(dice_coef)\n",
        "metric.append(tf.keras.metrics.TrueNegatives())\n",
        "metric.append(tf.keras.metrics.TruePositives())\n",
        "metric.append(tf.keras.metrics.FalseNegatives())\n",
        "metric.append(tf.keras.metrics.FalsePositives())\n",
        "metric.append(\"accuracy\")"
      ],
      "metadata": {
        "id": "JiKYxNbhiHE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the method"
      ],
      "metadata": {
        "id": "mewwvku2O9LA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_9y9j5Lu8zM"
      },
      "outputs": [],
      "source": [
        "# unet_model.compile(optimizer=ChosenOptimizer, loss=\"mse\", metrics=metric)\n",
        "unet_model.compile(optimizer=ChosenOptimizer, loss=loss_function, metrics=metric)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkRoOoAavDnc"
      },
      "source": [
        "Define callback methods each iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "885XaZU6wK4G"
      },
      "outputs": [],
      "source": [
        "callbacks = []\n",
        "\n",
        "#saves the weights of the best current epoch\n",
        "callbacks.append(tf.keras.callbacks.ModelCheckpoint(weights_path + \"/weights.{epoch:03d}.hdf5\",\n",
        "                                     verbose=1,\n",
        "                                     monitor='val_dice_coef',\n",
        "                                     mode=\"max\",\n",
        "                                     save_weights_only=True,\n",
        "                                     save_best_only=True))\n",
        "#adding logs\n",
        "callbacks.append(tf.keras.callbacks.CSVLogger(weights_path+\"/logs.csv\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PGM0a1g8W7a"
      },
      "source": [
        "Creating train and test datasets from images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLizp1Df9f29"
      },
      "outputs": [],
      "source": [
        "#divde to train and test data set\n",
        "trainPrecentage = 0.6\n",
        "trainigCouple=[]\n",
        "testingCouple=[]\n",
        "trainigCouple = inputsCouples[:(int)(trainPrecentage*len(inputsCouples))]\n",
        "\n",
        "testingCouple = inputsCouples[len(trainigCouple):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcftBJwVPrKv"
      },
      "outputs": [],
      "source": [
        "def formatToDataSet(pairList):\n",
        "  def expandPairDimensions(pair):# used for the nessecery input of the model\n",
        "    return (tf.expand_dims(pair[0,:,:],-1),tf.expand_dims(pair[1,:,:],-1)) \n",
        "   \n",
        "  Slices = tf.data.Dataset.from_tensor_slices(pairList)\n",
        "  mappedSlices = Slices.map(expandPairDimensions)\n",
        "  return mappedSlices.batch(BATCH_SIZE,drop_remainder=True)\n",
        "\n",
        "\n",
        "train_dataSet = formatToDataSet(list(trainigCouple))\n",
        "validation_dataSet = formatToDataSet(list(testingCouple))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataSet"
      ],
      "metadata": {
        "id": "iYKLeX1o3uZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def load_dataset(db_path,batch_size):\n",
        "#  element_spec = (TensorSpec(shape=(BATCH_SIZE, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(BATCH_SIZE, 64, 64, 1), dtype=tf.float32, name=None))\n",
        "#  db = tf.data.experimental.load(path=db_path,compression='GZIP',element_spec=element_spec)\n",
        "#  return db#.batch(batch_size,drop_remainder=True)\n",
        "\n",
        "#tf.data.experimental.save(train_dataSet,path=weights_path+\"/path\",compression='GZIP')"
      ],
      "metadata": {
        "id": "MM1_riqDsp0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the ratio between the black and white pixels in our datasets"
      ],
      "metadata": {
        "id": "z3dqYIz-PdJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train_dataSet.take(1):\n",
        "  y,id,c = tf.unique_with_counts(tf.reshape(i[1],[-1]))\n",
        "  print(y.numpy(),c.numpy())"
      ],
      "metadata": {
        "id": "7XNG3xkOmONt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onItuEqs9PGi"
      },
      "source": [
        "# Training The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxO92P8evDNb"
      },
      "outputs": [],
      "source": [
        "#in case of using gpu \n",
        "        # gpus = tf.config.list_logical_devices('GPU')\n",
        "        # strategy = tf.distribute.MirroredStrategy(gpus)\n",
        "        # with strategy.scope(): {}\n",
        "hist = unet_model.fit(\n",
        "        x=train_dataSet,\n",
        "        epochs=NUM_EPOCHS,\n",
        "        verbose=1,\n",
        "        callbacks=callbacks,\n",
        "        validation_data=validation_dataSet,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(hist.history.keys())"
      ],
      "metadata": {
        "id": "NcU-qrUFULec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plots part"
      ],
      "metadata": {
        "id": "Bpue9ZGfPrhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.xlabel('epoch')\n",
        "plt.xlim([0, NUM_EPOCHS])\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.savefig(weights_path+\"/accuracy.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QrnZd1gHO0K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "#plt.ylim([0, 1])\n",
        "plt.xlabel('epoch')\n",
        "#plt.xlim([0, NUM_EPOCHS])\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.savefig(weights_path+\"/loss.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sy53gwFsO64-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix\n",
        "def plot_mat(cm):\n",
        "\n",
        "  \n",
        "  classes = [ \"1 - Yes MS\",\"0 - No MS\"] # your y labels\n",
        "  import seaborn as sns; sns.set_theme()\n",
        "  sns.set(font_scale=2)\n",
        "  plt.figure(figsize = (20,14))\n",
        "  ax = sns.heatmap(cm, cmap=\"Blues\", annot=True, xticklabels=classes, yticklabels=classes, cbar=False,fmt=\",\")\n",
        "  ax.set(title=\"Confusion Matrix\", xlabel=\"Predicted Label\", ylabel=\"True Label\")\n",
        "  plt.savefig(weights_path+\"/ConfusionMatrix.png\")\n",
        "\n",
        "TN = hist.history['true_negatives'][-1]\n",
        "FP = hist.history['false_positives'][-1]\n",
        "FN = hist.history['false_negatives'][-1]\n",
        "TP = hist.history['true_positives'][-1]\n",
        "cm = [[TP,FP],[FN,TN]]\n",
        "plot_mat(cm)"
      ],
      "metadata": {
        "id": "e2SDIAfR38mS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Model"
      ],
      "metadata": {
        "id": "Gd2H1tOqny9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "listTestImages,listTestMasks,listTestFilesImages,listTestFilesMasks,testCouples = upload_db_images(r'/content/drive/MyDrive/DB_final_project/DB-TEST',ModolalityType,couples)\n",
        "imageArray = np.array(testCouples[73][0].dataobj)\n",
        "maskArray = np.array(testCouples[73][1].dataobj)\n",
        "\n"
      ],
      "metadata": {
        "id": "8dZILXdToaxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selecteImageArray = np.uint8(imageArray[:,:,245])\n",
        "cv2_imshow(selecteImageArray)"
      ],
      "metadata": {
        "id": "--LockEtpErQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selecteMaskArray = maskArray[:,:,245]*255\n",
        "cv2_imshow(selecteMaskArray)"
      ],
      "metadata": {
        "id": "zKaa6buf8h0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imageArray2, maskArray2 = crop_image(imageArray, maskArray)\n",
        "imageArray3, maskArray3 = resize(imageArray, maskArray)"
      ],
      "metadata": {
        "id": "gUZ2GTjn-0jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DevideImage(inputImage):\n",
        "    imageParts = []\n",
        "    \n",
        "    for i in range(0, 256, crop_size):\n",
        "        for j in range(0, 256, crop_size):\n",
        "            newImage = np.array(inputImage[i:i+crop_size, j:j+crop_size])\n",
        "            #newImage= (inputImage.crop(box))\n",
        "            #newMask= (inputMask.crop(box))\n",
        "            imageParts.append(newImage)\n",
        "\n",
        "    return imageParts\n",
        "\n",
        "\n",
        "devidedImageList = DevideImage(selecteImageArray)"
      ],
      "metadata": {
        "id": "U40h-r_hpkMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictedCouple=DevideImage(np.uint8(imageArray3[:,:,246])/255)"
      ],
      "metadata": {
        "id": "fVYLc8PwAlkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test final \n",
        "unet_model.load_weights('/content/drive/MyDrive/New_Final_Project_Weights/Loss_functions/BinaryCrossentropy-Ep100-B32-CrSize32-CrPrecent0.2-LR1e-05-T2-Gamma3.0-Depth4/weights.091.hdf5')#path to hdf5 file"
      ],
      "metadata": {
        "id": "FMG1WHwcAwtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictImage(listOfImages):\n",
        "  listPrediction=[]\n",
        "  for i in range(len(listOfImages)):\n",
        "    pred = unet_model.predict(np.expand_dims(listOfImages[i],0))\n",
        "    listPrediction.append(pred[0])\n",
        "  return listPrediction"
      ],
      "metadata": {
        "id": "WDQVShf3BGNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictedCouple= predictImage(predictedCouple)"
      ],
      "metadata": {
        "id": "_CrzJ0C6BKXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CombineImage(listParts):# combine the parts together\n",
        "  resImage=np.zeros((256,256))\n",
        "  k=0\n",
        "  for i in range(0, 256, crop_size):\n",
        "      for j in range(0, 256, crop_size):\n",
        "          resImage[i:i+crop_size, j:j+crop_size] = listParts[k][:,:,0]\n",
        "          k=k+1\n",
        "          \n",
        "  return resImage"
      ],
      "metadata": {
        "id": "VWz44R1DqcJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combinedImage = CombineImage(predictedCouple)"
      ],
      "metadata": {
        "id": "EDBrdKY4rmIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precentMask = (combinedImage > 0.5) * 1 #Filter Pixels with prediction lower then 50%"
      ],
      "metadata": {
        "id": "U_7Ugb_VBoVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow( precentMask*255)"
      ],
      "metadata": {
        "id": "bh7VTP5azpMl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6Htrkv0aVr2Z",
        "A1ssRFuf64ip",
        "LkBXkhdrxJzs"
      ],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}